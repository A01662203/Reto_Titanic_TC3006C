{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Age', 'Fare',\n",
      "       'Embarked_Cherbourg', 'Embarked_Queenstown', 'Embarked_Southampton',\n",
      "       'Alone', 'Large', 'Medium', 'Small', 'Female', 'Male'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Age', 'Fare', 'Embarked_Cherbourg',\n",
      "       'Embarked_Queenstown', 'Embarked_Southampton', 'Alone', 'Large',\n",
      "       'Medium', 'Small', 'Female', 'Male', 'Survived'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_clean.csv')\n",
    "test = pd.read_csv('data/test_clean.csv')\n",
    "gender_submission = pd.read_csv('data/gender_submission.csv')\n",
    "test = pd.merge(test, gender_submission, on='PassengerId')\n",
    "print(train.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['PassengerId', 'Pclass', 'Age', 'Fare',\n",
    "       'Embarked_Cherbourg', 'Embarked_Queenstown', 'Embarked_Southampton',\n",
    "       'Alone', 'Large', 'Medium', 'Small', 'Female', 'Male']]\n",
    "y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[['PassengerId', 'Pclass', 'Age', 'Fare',\n",
    "       'Embarked_Cherbourg', 'Embarked_Queenstown', 'Embarked_Southampton',\n",
    "       'Alone', 'Large', 'Medium', 'Small', 'Female', 'Male']]\n",
    "y_test = test['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500, 700],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "}\n",
    "\n",
    "# Crear el modelo de GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros encontrados\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir los datos de prueba usando el mejor modelo encontrado por GridSearchCV\n",
    "y_pred_rf = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# test['random forest prediction'] = y_pred_rf\n",
    "# test['Survived'] = y_test['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85371703\n",
      "Precision: 0.79738562\n",
      "Confusion Matrix:\n",
      "[[234  31]\n",
      " [ 30 122]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Accuracy: {accuracy:.8f}')\n",
    "\n",
    "# Evaluar la precision\n",
    "precision = precision_score(y_test, y_pred_rf)\n",
    "print(f'Precision: {precision:.8f}')\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "# Graficar la matriz de confusión con matshow\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.matshow(conf_matrix, cmap='Blues', fignum=1)  # Utilizar fignum=1 para evitar la creación de una nueva figura\n",
    "plt.title('Matriz de Confusión de Random Forest', pad=20, fontsize=18)\n",
    "plt.xlabel('Predicción', fontsize=14)\n",
    "plt.ylabel('Real', fontsize=14)\n",
    "\n",
    "# Agregar las anotaciones de los valores en la matriz\n",
    "for (i, j), val in np.ndenumerate(conf_matrix):\n",
    "    plt.text(j, i, f'{val}', ha='center', va='center', fontsize=16, color=\"black\")\n",
    "\n",
    "# Remover la barra de color\n",
    "plt.gca().set_frame_on(False)  # Remueve el borde alrededor de la matriz\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor precisión: 0.971222996711731\n",
      "Mejores hiperparámetros: {'dropout_rate': 0.0, 'learning_rate': 0.01, 'optimizer': 'adam', 'batch_size': 20, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Definir una función para construir y compilar el modelo\n",
    "def create_model(dropout_rate=0.0, learning_rate=0.001, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    if dropout_rate > 0.0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Definir los hiperparámetros a explorar\n",
    "param_grid = {\n",
    "    'dropout_rate': [0.0, 0.2],\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'batch_size': [20, 50],\n",
    "    'epochs': [50, 100]\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda manual de hiperparámetros\n",
    "best_score = -np.inf\n",
    "best_params = {}\n",
    "\n",
    "for dropout_rate in param_grid['dropout_rate']:\n",
    "    for learning_rate in param_grid['learning_rate']:\n",
    "        for optimizer in param_grid['optimizer']:\n",
    "            for batch_size in param_grid['batch_size']:\n",
    "                for epochs in param_grid['epochs']:\n",
    "                    model = create_model(dropout_rate=dropout_rate,\n",
    "                                         learning_rate=learning_rate,\n",
    "                                         optimizer=optimizer)\n",
    "                    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "                    score = model.evaluate(X_test, y_test, verbose=0)[1]  # [1] es para la precisión\n",
    "\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_params = {\n",
    "                            'dropout_rate': dropout_rate,\n",
    "                            'learning_rate': learning_rate,\n",
    "                            'optimizer': optimizer,\n",
    "                            'batch_size': batch_size,\n",
    "                            'epochs': epochs\n",
    "                        }\n",
    "\n",
    "print(f\"Mejor accuracy: {best_score}\")\n",
    "print(f\"Mejores hiperparámetros: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5006 - loss: 24.7540\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6550 - loss: 4.5559\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6449 - loss: 0.7197\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6289 - loss: 1.4383\n",
      "Epoch 5/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5894 - loss: 0.9399\n",
      "Epoch 6/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6373 - loss: 0.7845\n",
      "Epoch 7/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6770 - loss: 0.9068\n",
      "Epoch 8/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6746 - loss: 0.6889\n",
      "Epoch 9/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6790 - loss: 0.6221\n",
      "Epoch 10/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6554 - loss: 0.7915\n",
      "Epoch 11/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7136 - loss: 0.5971\n",
      "Epoch 12/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7404 - loss: 0.5413\n",
      "Epoch 13/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7245 - loss: 0.5557\n",
      "Epoch 14/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7482 - loss: 0.5380\n",
      "Epoch 15/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6681 - loss: 0.7787\n",
      "Epoch 16/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7197 - loss: 0.6508\n",
      "Epoch 17/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7584 - loss: 0.5129\n",
      "Epoch 18/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7623 - loss: 0.5265\n",
      "Epoch 19/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7510 - loss: 0.5325\n",
      "Epoch 20/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7491 - loss: 0.9406\n",
      "Epoch 21/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7487 - loss: 0.9823\n",
      "Epoch 22/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7802 - loss: 0.5759\n",
      "Epoch 23/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6695 - loss: 0.8542\n",
      "Epoch 24/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7642 - loss: 0.5367\n",
      "Epoch 25/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7733 - loss: 0.5518\n",
      "Epoch 26/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7613 - loss: 0.5364\n",
      "Epoch 27/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7441 - loss: 0.5846\n",
      "Epoch 28/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7501 - loss: 0.7392\n",
      "Epoch 29/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8076 - loss: 0.4631\n",
      "Epoch 30/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7702 - loss: 0.6889\n",
      "Epoch 31/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7536 - loss: 0.5394\n",
      "Epoch 32/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7834 - loss: 0.4810\n",
      "Epoch 33/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7690 - loss: 1.2779\n",
      "Epoch 34/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7089 - loss: 0.8556\n",
      "Epoch 35/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7737 - loss: 0.5471\n",
      "Epoch 36/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7534 - loss: 0.5469\n",
      "Epoch 37/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7914 - loss: 0.4942\n",
      "Epoch 38/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8081 - loss: 0.4559\n",
      "Epoch 39/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8030 - loss: 0.4773\n",
      "Epoch 40/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7389 - loss: 1.2757\n",
      "Epoch 41/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7528 - loss: 0.7590\n",
      "Epoch 42/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7667 - loss: 0.5259\n",
      "Epoch 43/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7428 - loss: 0.5754\n",
      "Epoch 44/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7760 - loss: 1.0380\n",
      "Epoch 45/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7580 - loss: 0.7294\n",
      "Epoch 46/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6699 - loss: 0.6690\n",
      "Epoch 47/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7447 - loss: 0.5452\n",
      "Epoch 48/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7584 - loss: 0.5220\n",
      "Epoch 49/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8020 - loss: 1.5257\n",
      "Epoch 50/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7844 - loss: 0.4842\n",
      "Epoch 51/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7783 - loss: 0.5102\n",
      "Epoch 52/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7951 - loss: 0.4674\n",
      "Epoch 53/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7843 - loss: 0.5016\n",
      "Epoch 54/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6811 - loss: 0.5892\n",
      "Epoch 55/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7537 - loss: 0.5279\n",
      "Epoch 56/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7513 - loss: 0.5318\n",
      "Epoch 57/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7935 - loss: 0.4602\n",
      "Epoch 58/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7817 - loss: 0.4743\n",
      "Epoch 59/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7992 - loss: 0.4891\n",
      "Epoch 60/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7743 - loss: 0.4916\n",
      "Epoch 61/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7623 - loss: 0.7945\n",
      "Epoch 62/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7977 - loss: 0.4751\n",
      "Epoch 63/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7869 - loss: 0.4961\n",
      "Epoch 64/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7793 - loss: 0.4990\n",
      "Epoch 65/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8066 - loss: 0.4494\n",
      "Epoch 66/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8294 - loss: 0.4256\n",
      "Epoch 67/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7892 - loss: 0.5136\n",
      "Epoch 68/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7894 - loss: 0.4826\n",
      "Epoch 69/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7784 - loss: 0.4874\n",
      "Epoch 70/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7400 - loss: 2.6787\n",
      "Epoch 71/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7726 - loss: 0.5697\n",
      "Epoch 72/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7982 - loss: 0.4659\n",
      "Epoch 73/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7527 - loss: 0.5126\n",
      "Epoch 74/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7460 - loss: 0.5292\n",
      "Epoch 75/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7982 - loss: 0.6788\n",
      "Epoch 76/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7854 - loss: 0.4989\n",
      "Epoch 77/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7160 - loss: 0.5954\n",
      "Epoch 78/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7768 - loss: 0.5410\n",
      "Epoch 79/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6217 - loss: 0.6631\n",
      "Epoch 80/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7525 - loss: 0.5608\n",
      "Epoch 81/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7009 - loss: 0.5971\n",
      "Epoch 82/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7117 - loss: 0.5570\n",
      "Epoch 83/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7525 - loss: 0.5161\n",
      "Epoch 84/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7153 - loss: 0.5922\n",
      "Epoch 85/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6668 - loss: 16.2494\n",
      "Epoch 86/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7621 - loss: 0.5149\n",
      "Epoch 87/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7681 - loss: 0.5034\n",
      "Epoch 88/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6901 - loss: 0.6164\n",
      "Epoch 89/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6775 - loss: 0.6173\n",
      "Epoch 90/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7360 - loss: 0.5676\n",
      "Epoch 91/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7043 - loss: 22.8734\n",
      "Epoch 92/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6737 - loss: 0.6394\n",
      "Epoch 93/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6286 - loss: 0.6409\n",
      "Epoch 94/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6320 - loss: 0.6507\n",
      "Epoch 95/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6163 - loss: 0.6623\n",
      "Epoch 96/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6024 - loss: 0.6600\n",
      "Epoch 97/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6375 - loss: 0.6575\n",
      "Epoch 98/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6177 - loss: 0.6653\n",
      "Epoch 99/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6139 - loss: 0.6674\n",
      "Epoch 100/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6111 - loss: 7.1672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3a894d490>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el mejor modelo encontrado\n",
    "best_model = create_model(dropout_rate=best_params['dropout_rate'],\n",
    "                          learning_rate=best_params['learning_rate'],\n",
    "                          optimizer=best_params['optimizer'])\n",
    "\n",
    "best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de validación: 0.6354916067146283\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step\n",
      "Precision: 0.00000000\n",
      "[[265   0]\n",
      " [152   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAJICAYAAAAw3d0TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEJ0lEQVR4nO3dd3hUZf7//9fMJJk0Ukgg9NARpRcVROkgIoorytcCiIu9AVY+sIoVBQVRxEoR9ce6KiiKsgJSRGWl6lpAkY4EQkkCAZJM5v79kZ2RIZmQOwlJgOfjuuaCnPqek3POvHLOfe5xGGOMAAAALDjLuwAAAHD6IUAAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1kLKuwAAZ66XX35Z+/fvV+fOndW1a9fyLgdAKXLQkRSAU+Gll17Sfffdp9atW2v58uWKjo4u75IAlCJuYZzmbrrpJjkcDt10003lXYrfzJkz5XA4VLdu3fIu5bQ1Y8YMdejQQTExMXI4HHI4HHrxxRfLrR7b/WzVqlV68MEHlZycrPnz51fo8DB27Fg5HA516dKlvEupcDiWz3xbt271n2O2bt1qNe8ZHSB8Jwbf65///OdJ5+nbt2/APLYb9GRefPFFjR07VuvXry/V5SK/vXv36tlnn1XPnj1Vq1YtRUREKCoqSnXr1lX//v31xhtvKC0trbzLzOeFF17QzTffrJUrV+ro0aOqWrWqkpKSFBUVVd6lFcnBgwd17bXXKioqSp9//rmqV69e3iVVWMefa3wvp9OpmJgYtWjRQnfddZd++eWX8i6zWHzhw/ee1q1bV+j0vmlnzpxZNgWixM7oAHGiGTNmFDr+zz//1L///e9TWsOLL76oxx9/vNQCRPXq1dWkSRNO0scxxuiZZ55RvXr1NGrUKC1atEi7du1SSEiIXC6Xtm3bpk8++US33Xab6tatq+nTp5d3yQGef/55SdK9996rI0eOaM+ePUpJSdEtt9xSbjUVdT8zxmjIkCH6888/NXfuXJ177rllVOHpLSoqSklJSUpKSlJCQoIOHz6s//73v5o6dapatWpV4fZRW8YYPfLII+VdBkrZWREgEhMTFRUVpUWLFmnHjh1Bp5s1a5Zyc3NPq8t148aN04YNGzRu3LjyLqVCMMZo0KBBGj16tI4cOaILLrhAH330kQ4ePKhDhw4pIyND6enpmjt3rvr166f09HTNmzevvMv2S01NVUpKiiTplltuUWhoaDlXlKeo+5nD4dC8efOUlZWlzp07l1F1p78HHnhAKSkpSklJUWpqqo4ePaqPP/5YtWvXVk5Ojm677TZt3LixvMsskS+//FJfffVVeZeBUnRWBIioqCgNGDBAXq9Xb7/9dtDpfFcoKlJ7AtgZP3683nvvPUnS8OHD9d133+lvf/ub4uLi/NPExMSof//+mjdvnpYtW6ZatWqVU7X5HTlyxP//itxuAKeW2+3WlVde6d+XPR5Poeeuiu7yyy+XJD388MOi3f6Z46wIEJI0dOhQSXn35QragVesWKHffvtN9evX1yWXXFLosjZu3KgJEyaoR48eatCggSIiIhQTE6PWrVtrzJgx2rdvX755fO0xtm3b5q/nxHufPic2avnjjz906623ql69enK73QFXSII1bjux/Udhr+K081i5cqX69++vxMRERUREqEmTJho9erQOHz5cpPnT09P19NNP64ILLlB8fLzcbrdq166t6667TitXrrSuR5L27dunJ598UpLUvXt3TZw4MWC7FuSSSy7RSy+9VOC4pUuX6pprrlHNmjXldruVmJio7t27a8aMGcrNzS1wnhMb5C1evFh9+/ZVlSpVFB4erqZNm+rxxx/XsWPH8q3rxMZq9erV8/+Ojh9et27dk94rLqzRo8fj0RtvvKEuXbooMTFRoaGhSkhIUJMmTTRw4MACL5cXpRFlWW4vW1988YV69uypuLg4RUdHq2XLlho/frxycnKKNH9KSooeeeQRtWzZUrGxsQoPD1f9+vU1bNiwU9pGoVOnTv62Lz///HPQ6datW6ebb75ZDRo0UGRkpP89BjsfHa+kx3JRjBs3Tk6nU6tXr9aHH35Y7OX88ccfuueee9S0aVNFR0crMjJSTZs21fDhw7V9+/YC5ylKI1nf8VfQ+eLE+T/66CP16tVLVatWldPp1NixYwOmX7dunQYPHqzk5GSFh4crPj5eHTt21IsvvqisrKwC139iY9U1a9bo2muvVfXq1eV2u1W/fn2NHDlSBw8eLHD+nJwcLVy4UPfee6/atWun6tWrKywsTFWrVlXv3r01e/bsUxPczBnsscceM5JMcnKy8Xq9pkGDBkaSWbZsWb5pb775ZiPJPPHEE2bJkiVGkpFktmzZkm/a5ORk/3iHw2Hi4uKMw+HwD6tZs6bZsGFDwDwTJkwwSUlJxul0GkkmJibGJCUlBbx8tmzZ4l/We++9Z6Kjo40kExkZaaKiokxycrJ/2iFDhhhJZsiQIQWuL9irUqVKhb7HwkybNs3/PiSZ2NhYExYWZiSZc845x0ycONG/3QuycuVKk5SU5J/f5XIF1ONwOMwzzzxjVZMxxowfP96/jK+//tp6/uONGDEi3+/Y5XL5h3Xr1s1kZGTkm8+3z3Xu3NmMHz/eOByOAveRrl27Go/H45/vm2++MUlJSSYxMdE/TWJiov/31a5dO/+0vv1vxowZQesPtl94PB7Ts2dP/zp8vz+32x0wrKjLK6/tZcO3Dt8rLi7OhISEGEnmkksuMaNGjfLXUJBPP/3UfwxKMqGhoSYqKsr/c1hYmHn77beLVZtvGY899liB471er39dffv2LXCaRx99NGBbRUZG+o9HSaZ69epm7dq1Bc5b0mO5MDNmzAjYn3z7UKNGjUxOTk7QbRFsv37jjTdMaGiofzq3220iIiL8P8fExJgvv/wy33zH72PBHH/OL2z+kSNH+vfx+Ph443K5An53kyZNCvhdxMbGBtTcokUL8+effwbdVsnJyea9997zzxMbGxvw+znvvPPMoUOHCq3ft22O32clmWuuucbk5ubmm/f4zxvbz4KzJkAYY8yTTz5Z4Enw8OHDJjo62jidTrN9+/aTBoiBAweal19+2WzatMlkZWUZY4zJysoyixYtMueff76RZNq0aVNgTUU5+R//C42OjjYXXHCBWbVqlX/8xo0b/f8/2Ym9IGlpaaZp06b+Oo8dO1bkedesWeM/+Xbp0sX8+uuvxhhjsrOzzezZs01cXJyJi4sLetLZsmWLf/yAAQPMmjVr/CeTPXv2mH/84x/+5c+dO7fIdRljTO/evf0fvCXx8ssv+7f/rbfeanbv3m2MydtPJk2a5K9v4MCB+eb17XNxcXHG6XSaUaNGmdTUVGOMMenp6ebRRx/1L3vatGn55i/KwVySAPHOO+8YSSY8PNy89dZb/pOR1+s1e/bsMXPmzDFXX311kZdX3tvrZD755JOAE+j27duNMcYcOXLEvPLKKyYsLMy/Pxb0AfOf//zH/4F62223mV9//dUfZLZt22buvPNOI8mEhIQEHKNFdbIAsWzZMv8099xzT77xkyZNMpJMpUqVzLhx4/zb3uPxmNWrV5tu3boZSaZWrVr5PnhKeiyfzIkBYtu2bf6g+uqrrwbdFgXt13PnzvWHt0ceecRs3brVeL1e4/V6zYYNG8w111zjDxHbtm0LmLe0AoTvA/mhhx4ye/fuNcYYc+zYMbN161ZjTF7Q9C3jyiuvNJs3bzbG5H02zJo1y/9HUseOHfOFYd+2ioyMNG632wwbNsy/r2ZmZpopU6b4Q8U//vGPfDWuXLnSXH/99Wb+/PkmJSXFeL1eY4wx+/fvN5MnTzYxMTFGkpk8eXK+eQkQQZwYILZv326cTqeJiooKOJimT59uJJmePXsaY8xJA0RhDh065P/ruqC/gm0DRHJycoGJ08c2QOTk5Jju3bsbKe9Kyc6dO4s0n0+fPn2MJNO4cWNz5MiRfOMXLFgQUPuJBgwYYCSZQYMGBV2H76+eli1bWtVWq1atgN9jcRw5csRUrlzZSDLXXXddgdO89NJL/vd44ofG8X/tBvtQ+Nvf/mYkmR49euQbd6oDxB133OH/oLcRbHnlvb1O5txzz/V/eBT019drr73mX39BHzDt27cPetL2uffee/0fGraCvfdjx46Zjz/+2NSuXds/zZo1awKmSU1NNZGRkcbhcJhFixYVuPycnBzTtm1bI8lMmjQpYFxJj+WTOTFAGPPXlarq1aubzMzMgOmDBYisrCxTs2bNk4bIK664wkgy9913X8Dw0goQkszIkSODLsO3r3Xq1KnAq2Xz5s3zL+eDDz4IGHf8tgp2Lvdd/WjYsGHQGoL54IMPjCTToEGDfONKEiDOmjYQklS7dm316NFDmZmZ+te//uUf7ms8efPNN5d4HdHR0f7W5ytWrCjx8u6+++5SbUx3xx13aPHixYqKitK8efNUs2bNIs+blpbmf8z1wQcfVERERL5pevfurQ4dOhQ4/4EDBzRnzhxJKvSRrsGDB0uSfvjhB+3Zs6fI9e3fv1+SVLly5SLPc6KFCxfqwIEDkpTv3qbPnXfe6X+ccfbs2QVO43a79cADDxQ47sorr5Qk/fjjj8Wus7h8jUl9T3qUVEXeXj/++KO/fcKYMWPkdOY/3d1yyy1Bj4EffvhBq1atUmhoqO6///6g6/Htr4sWLQra1uNknn/+eVWrVk3VqlVTlSpVFBERof79+/ufGnv++efVpk2bgHnee+89HTlyRO3atVP37t0LXG5ISIiuu+46SQp4RL2kx3JxjR49WjExMdq9e3eRO0b74osvtGvXLiUlJfnbshXE93s4VY/iO51OPfzwwwWOO35f+8c//iGXy5Vvmn79+un888+XFPw4kPL21YL4joNNmzYFNLYuir59+0rKa0Oye/duq3kLc1YFCOmvxpS+hmKbNm3S119/rbi4OPXv37/Iy/nss880cOBA1a9fX1FRUQGNEn3hZOfOnSWu96KLLirxMnyee+45vfXWW3I6nXr33XfznZBOZu3atfJ6vZKkbt26BZ0u2LjvvvsuYH7fCfPE13nnneefx9fo1MbJGk4WZvXq1ZLywmbjxo0LnMblcvnfo2/6E5133nlBg1+NGjUkyf/BW5Yuu+wy/6OWffr00ezZs/Xnn38We3kVeXv51hUSEqKLL764wGmcTmfQxnW+PwC8Xq+aNGkSdH+99NJLJUmZmZn+EGsrMzNTe/bs0Z49e7Rv3z5/g7f4+Hh98803BQYYX30//fRT0NqqVaumJ554QlLgsVTSY7m4EhIS9NBDD0nKe2KqKNvL9z4PHjyo6tWrB32fvn5SinPOKIqGDRuqatWqBY47fl8r7PHlnj17Bkx/osqVK6thw4YFjvMdB5IKbEx56NAhTZgwQZ07d1bVqlUVFhbm/0yKjIz0T7dr166g9dk6675M66qrrvIflL/99pv/0ajrr79e4eHhJ53f6/XqxhtvDEiQISEhio+PV1hYmKS8JwyOHTumzMzMEtcbbIe19dFHH2nUqFGS8oKETVjy2bt3r///hV25CPZY5PEfVEW9smCTtBMSErRz585in8Slv97jya7M+N7j8dvkeJUqVQo6b0hI3mHn8XiKU2KJdOrUSc8995zGjBmjBQsWaMGCBZLy3k+PHj00ePBgqy+9qsjby7euxMREud3uk9Z2It/+mpube0r21+M99thj/is4R44c0c8//6wnn3xSn376qW666SYtXbo04APk+PqOHj2qo0ePWtVW0mO5JEaMGKEpU6YoJSVFzzzzjF544YVCp/e9z+zs7CL9HoqyLYqjsHOx7b5WkuNAUr6nh3777Td179494I/WyMhIxcXF+a+8+bZdaXwu+Zx1VyDcbrf/kt60adM0a9YsSSr00tjxpk2bptmzZ8vlcunRRx/V77//rqysLB04cMDfEcyAAQMkqVQemynoUpit77//XoMGDZIxRsOGDQt6qfhU813ejYiIkMlrf3PSl833E/iuXJRGL59FvYpRkqsd5eXBBx/Uli1bNGnSJPXv319Vq1bVzp07NXPmTHXr1k3XXHNNkR9v9KnI26u46/Ttr+ecc06R99fS6IQuMjJS7du318cff6zu3bvr999/1w033JDvfOKr7/bbby9SbaXdLX9xRUZG6tFHH5UkvfLKK0Efv/Txvc9LL720yL+HU6Eo5+LyOg6GDh2qnTt3qm7duvrggw+0f/9+ZWZmau/evUpJSQm46lCa2+esCxDSX2HhxRdf1M6dO9WsWTO1a9euSPP6vk9j2LBhevzxx9WwYcN891ZL6/5yadi2bZuuuOIKHT16VF27dtXUqVOLvazjE3hhl8GCjatWrZqkvL8QNm3aVOw6gvHdB05NTS12+xPfeyysx1Lpr9tTVapUKdZ6SsL3l0hhfSOkp6cXuowaNWpo+PDhmjt3rvbs2aMff/xRw4YNkyR9+OGHevXVV4tUS0XeXr7aUlNTgz5/L518f928eXOp/tVWVE6nU6+++qpCQkK0dOnSfN/l46vvv//9r/WyS3osl9Qtt9yiRo0aKSsrS4899lih05bkfUqlc7ycTFH3tVNxHOzYsUPffvutpLy2FQMGDMjXDuxUfSadlQGiXbt2at68ubKzsyXZNZ70nShbt25d4PjDhw/rP//5T9D5fWHjVKXk42VkZOjyyy/Xnj171LhxY3300Ucl6hq5TZs2/vqXLFkSdLpg3dV27NjRn7yL8sVmtoYOHeq/1zd27Ngib2PfvWBJ/iC5c+dO/fbbbwVOn5ub63//7du3L0nJxRIfHy8p+Ie21+sNeo81mObNm+vNN9/0t7lZuHBhkearyNvLV5vH4wkaKL1er5YuXVrgON+2yM7O1ty5c09JjSfTqFEj3XDDDZLyGtcdfxvHV9/KlSut7/uX9FguqZCQED311FOS8r5C4Keffgo6re997tq1q1h/GJzseJFU6Dm7KI7f15YtWxZ0ukWLFkkq3ePg+PcV7HPJt97SdlYGCCmvHcD999+v+++/XzfeeGOR54uNjZWU10K7IE8++aQOHToUdP6YmBhJOuXfAunxeHTttdfqp59+UkJCgubPn+8/kIorLi5OvXr1kpTXKrygRL9o0SJ/Gj5R1apV/S2JJ0yYEPQDx8e20VxiYqK/BfPixYt1//33nzREfPPNN7rvvvv8P/fs2VMJCQmSgj9V8Prrr/vvy/puh5Wlli1bSpLmzp1b4Pt7++23gzbgLeyvI0n+1vhFvXVWkbdXixYt1LRpU0nS008/HRAUfaZPnx50W7Vr185/Qh49erRSU1MLXd+pahQ7atQoOZ1Obd68OeALAQcNGqSIiAjl5ubqrrvuKvQJEK/XG3DOKemxXBquueYatWvXTl6vV//3f/8XdLp+/fr5n+K57777TtrO5MTfg+94+fPPPwvs5Xbv3r168803bcsP0KJFC/8Xxz311FMF/i4+//xzf1ApzePA95kkFfy5dOjQIX9YK3VWD32eZk7sB6KoCusHYsyYMUb/6zjm9ddf93cktXv3bjN8+HAjySQkJAR9nveGG27wdyZy4MCBAtdv81xusOfzfR3chIWFmaVLlxb1rZ/UqlWr/D0MduvWzd/jZk5Ojnn//fdNfHx8oZ3P/PHHH/7tU6VKFTNt2jSTlpbmH5+ammo++ugjc9VVV5levXpZ1+f1es3AgQP9269Dhw5mzpw5Jj093T9NRkaG+fTTT81VV11lHA5Hvuf3j+8Y6bbbbjMpKSnGmLwOXV566SV/hy6FdYxU3GfOi/K7X7RokX+aYcOGmX379hlj8jpemjhxogkLC/P3zXDifnHppZeaoUOHms8//9wcPHjQP3z//v3mySef9Pei9/rrrwfMV9SOpMp6e53MnDlz/PMOHDjQ7NixwxhjzNGjR82rr75q3G73STuS8nV+VK9ePfPBBx8E9F+wc+dO884775gePXqYYcOGWdfnqy1YHxg+vv5T6tSp4z/nGGPM5MmT/cvo2rWrWbFihb8PAq/Xa3799VfzwgsvmKZNm5p33nknYJklPZZPpqB+IE50/L7sewXrSMq3b7Zq1cosWLAgYDts3rzZvPbaa6Z9+/bmySefDJg3NzfX33dKkyZNzKpVq4zX6zW5ublmyZIlpmnTpv7jpaBai7KPGhPYkVT//v39HUllZ2ebd99919+ZU2EdSRW2nYOdG7xer6lTp46R8nqqXL16tX/ct99+a9q0aeM/50oyS5YsKdJyi4IAUYDCAsTBgwfNOeec4x/vdDoDut297bbbCj3ZLlu2zD+ty+Uy1atXN8nJyQE1lkaA8B0woaGhhXZpnZSU5O/xrKhef/31fN21+k6yRen+du3ataZu3br++X3dwp7Y9WpxOg4yJu+AevzxxwO6uZXyeus7vstsSaZy5cpm1qxZ+ZZxYtfM8fHx/l77fCfrk3XNHExJA4QxxgwePDjgffh6cpRk7r777qD7RefOnQPmi4mJ8Z/YfK8BAwbk63TJtivrstpeRTF69OiA93d8bRdffPFJu7L+8ssvA07ALpfLJCQkmMjIyIDlnsoAsXbtWv+0U6ZMCRg3fvz4gG7Dw8LCTEJCQkAXypLMu+++m2+5JT2WC1OUAGGMyde1erAO0t59992AbR4SEmISEhLydcP+1FNP5Zt3wYIFAdsjMjLShIeHGymva+3Zs2eXOEAYk9cJ3vHbMy4uLqBb8ebNm5tdu3YF3VbFCRDG5IWX44+3yMhI/7aKjIwMCGqlGSDO2lsYxRUXF6dvv/1Ww4cPV926deVyuRQSEqIuXbpo9uzZeu211wqd/5JLLtH8+fPVo0cPxcbGas+ePdq2bdspe3Y5JyfH/3x5sJdt5ze33nqrvvnmG/Xr10+VK1dWVlaWkpOTNWrUKH3//fcnvVXSunVr/fLLL5oyZYp69OihxMREHTp0SF6vV40aNdL111+vf/7zn/5Op2w5HA49+uij2rx5s5555hl169ZNNWrUUHZ2tjwej5KTk9W/f3+99dZb2rp1qwYNGpRvGRMnTtRXX32lq6++WklJSTp8+LAqVaqkrl27avr06Vq4cGGhj1ydatOnT9fkyZPVqlUrRUREyOv16qKLLtL777+vl19+Oeh8L7/8sp577jlddtllatSokYwxOnr0qGrUqKErrrhCH330kT744IMCO10qTEXeXk899ZQ+++wzdevWTTExMcrKylLTpk317LPPavHixf7Hr4Pp2bOnNm3apHHjxqlTp06KjY1VWlqanE6nzj33XP3973/XvHnzCt3uJdW6dWtddtllkqRnnnkm4JbDgw8+qA0bNmjEiBFq0aKFwsPDlZaWpujoaLVv314PPfSQvv32W11//fX5llvSY7k0PPvss0V6KuGGG27Qpk2bNGbMGLVr107R0dFKS0tTeHi4WrVqpbvvvluLFi0qsLOn3r176+uvv9bll1+u+Ph45ebmqnbt2nrkkUe0Zs0af0PNkhoxYoRWr16tG2+8UbVr19aRI0cUERGhCy+8UBMnTtT333+f73Hc0nD55Zdr+fLl6tu3r+Li4uTxeJSYmKihQ4dq7dq1QTsaKymHMWXQmg8AAJxRuAIBAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEKjQpk6dqnr16ik8PFxt27bV119/Xd4lAZC0fPly9evXTzVq1JDD4dDHH39c3iWhjBEgUGG9//77Gj58uEaPHq1169bp4osvVp8+fbR9+/byLg0462VmZqply5aaMmVKeZeCcuIwxpjyLgIoyAUXXKA2bdro1Vdf9Q9r2rSp+vfvr3HjxpVjZQCO53A4NHfuXPXv37+8S0EZ4goEKqTs7GytWbNGvXr1Chjeq1cvffvtt+VUFQDAhwCBCmnfvn3Kzc1VUlJSwPCkpCSlpKSUU1UAAB8CBCo0h8MR8LMxJt8wAEDZI0CgQkpMTJTL5cp3tWHv3r35rkoAAMoeAQIVUlhYmNq2bauFCxcGDF+4cKE6duxYTlUBAHxCyrsAIJiRI0dq0KBBateunTp06KA33nhD27dv1+23317epQFnvcOHD2vTpk3+n7ds2aL169ercuXKqlOnTjlWhrLCY5yo0KZOnarx48dr9+7datasmSZNmqRLLrmkvMsCznpLly5V165d8w0fMmSIZs6cWfYFocwRIAAAgDXaQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBCo0LKysjR27FhlZWWVdykACsAxevaiHwhUaBkZGYqNjVV6erpiYmLKuxwAJ+AYPXtxBQIAAFgjQAAAAGsECAAAYO2M/DbOiNZ3l3cJKCXGmytXUntVvfhhOZyu8i4HpeTgqinlXQJKiXG5Nfofj8m43DrmKe9qUFrCi5AOzshGlAQIoGIjQAAVW1ECBLcwAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArBEgAACANQIEAACwRoAAAADWCBAAAMAaAQIAAFgjQAAAAGsECAAAYI0AAQAArIWUdwE4MxljZDJ3Kzd9i7yZu2WOHZSMR3KFyxlVTa7E5nJVqlXoMnIP/q7cAxvkPZoq5WZJIRFyhifIGddAIQnnBkzr2f+rPDu+KnR5ofUvlysmucTvDYC04IvP9dKLE7V+3VplZWWpceMmGjRkqG6/8y45nfxtejYgQOCU8B7eqZw/5v3vJ4cc7ljJGSKTlS5v+ua8V1I7hVa/IN+8xpurnK0L5M3Ymjd3WIwUVkkm54i8h3bIeI7mCxB+IRFyuOMKHOVwuUv+xgBowvhn9ejoUZKkevXrKzoqWj/++IPuH3Gvlny1SO9/OJcQcRYgQOCUcYTFylW1lVxxDeUICZeUFw48Kd8rd+9a5e5ZLWdkklyxdQPmy9m+WN6MrXJE1VBo7S5yhsf7xxnPUXmPpAZdp7NSssKSu5+S9wNAWvndd3pszP/J6XRq+tvvauD/u06S9OMPP+iKvr312afzNPnFiRox8oFyrhSnGhERp4QzMklhTa9XSGIzf3iQJIfTpdAaHeSsVEeSlLv/54D5cjO2yZv2uxzueIU16BcQHiTJERIhV0ydU/8GABTouXFPyRijoTcP84cHSWrRsqWenTBRkvTC+GeVk5NTXiWijBAgcEo4XGFyOILvXs5KtSVJJis9YHhu6o+SpJCktnI4uUAGVCQZGRn6avEiSdKQoX/PN/7qAdcoJiZG+/fv17KlS8q6PJQxztAoHyY371+n669BXo+8h3bmDY6pq9xDu+Q9uFEmO0NyueWMqiFXQlM5XGHBF3tsn7K3fil5jkjOMDkjE+WMbyKnO/aUvh3gbPDD+nXKzs5WeHi4Wrdpk298aGio2rZrryVfLdaq7/+jHj17lUOVKCsV8grE1KlTVa9ePYWHh6tt27b6+uuvy7sklCJjjHLTNkmSnFHV/xp+dJ8krxQaJc/etcr542PlHvhV3sO75E3fLM+fK5S14f8rtA2EObpP3rTf8+bJ2CJPyipl//qePCmrT/XbAs54m37/XZJUu04dhYQU/PdnvXr1A6bFmavCXYF4//33NXz4cE2dOlUXXXSRXn/9dfXp00e//PKL6tTh3veZIHf/L3lhweGUq0pL/3CTcyTvP56jyt27Vs6Yugqp0VGOsBiZY/uUs2OZzNFUZW/5XO5zrgu4EuFwufMeDY1vJEdYrORyyxw7IE/qD/Ie3ChPyn8kV5hCqrQo67cLnDEOph2UJMXFxQedJi4+b1za/6bFmavCXYGYOHGi/v73v2vYsGFq2rSpXnzxRdWuXVuvvvpqeZeGUuA9kirPrrwrSiHVLwi8teD9X6Mr45UjLEah9S6VMzxeDqcrr1Fm/b6SM0TKOazcAxsCluuKq6/QWpfIGVVdjtDI/81TRWHJPfwhxbP7PzK52WXyPoEzUdaxY5KksLDgtxHd7rzHpY8ePVomNaH8VKgAkZ2drTVr1qhXr8D7Zr169dK3335b4DxZWVnKyMgIeBlvblmUC0verAxlb/5MMrlyxjeSq0rrwAmOaw/hSmwmh8MVMNoRGiVXXKO8ZR3aXuT1hlQ7X3K4JG+2vId3Fv8NAGc5d3jeE1XZ2cGDeFZWliQpIiKiTGpC+alQAWLfvn3Kzc1VUlJSwPCkpCSlpKQUOM+4ceMUGxsb8PLsWVMW5cKCyclUzh+fSJ4jcsYkK7ROdzkcjsCJjuvoyeEu+BKp43+PdZrsjCKv2+EKkyO8ct58Jzz1AaDo4uNOfnsi7eDJb3PgzFChAoTPiR8sxpj8Hzb/M2rUKKWnpwe8QpLalkWZKCLjOabsP+bJZGfkdQ5V99J8VxckyXl8aHDmHy8p70qCJBljV4TvkVLb+QD4NWyUdwVwx/bt8ng8BU6zZcvmgGlx5qpQASIxMVEulyvf1Ya9e/fmuyrh43a7FRMTE/ByBPvwQZkzudnK3vyZzLEDckRWVVj9vkH7d3CERUuh0XnzZRV8hcF35cERGlX0GoxXJivNej4AgVq2aq3Q0FAdO3ZM69auzTc+JydHa1avkiS1Pz9/N/U4s1SoABEWFqa2bdtq4cKFAcMXLlyojh07llNVKC7jzVXOls9ljuyRI7yywur3K7QPB0lyxTWQJOUe3FjA8jzKPZj3aJgzuvAv4jpe7v5f876MSw45o2sW/Q0ACBATE6Nu3XtIkt6eMS3f+I8+/EAZGRlKSEjQJZ27lHF1KGsVKkBI0siRI/XWW29p+vTp+vXXXzVixAht375dt99+e3mXBgvGeJWz7d/yHt4lR1iMwhpcEdCldTAhVVtLzlCZzN3ypKyW+d8tB+P1KGfHsrwOolxuuRLP+2tdudnK3vqlvJl78tXg2f+z/6kPV0LTvKscAIrtoUdGy+FwaMb0t/T+P2f7h//4ww965MGRkqQRDzxU6JMaODM4jKl4N4WnTp2q8ePHa/fu3WrWrJkmTZqkSy65pMjzR7S++xRWh6LIPfibcrblXUlyuGOlkMgCp3OERCqs3qWB86ZvUc7WBZLx5n27ZlglmWNpkjdbcoYotG6fgO/DMJ4sZf30Vt4PLrccYZUkhzOvwWRuXotwZ6U6Cq3Xh+6xK4iDq6aUdwkogefGPa2xj46R9Ne3cf7880/yer3qc1lffTDnE7lc3Eo+nYUX4VRZIQNESREgyp9n/6/y7Pjq5BOGVlL4eYPzDfYe3S/PnjXyHt4l5R6TQiLkjK6lkKS2+b5gy5hc5ab+IG9miszRAzKeo5LxSK5wOSOryBXfRM64hkEb4qLsESBOf5/P/0wvT56kdWvXKCcnRw0bNtKgIUN1x113Ex7OAAQIABUSAQKo2IoSICpcGwgAAFDxESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANZCbCbevn17sVdUp06dYs8LAAAqFqsAUbduXTkcDuuVOBwOeTwe6/kAAEDFZBUgBg8eXKwAAQAAzixWAWLmzJmnqAwAAHA6oRElAACwRoAAAADWrG5hFCQ3N1f/+te/tGjRIv3555/KysrKN43D4dDixYtLuioAAFBBlChAZGZmqlevXlq5cqWMMXI4HDLG+Mf7fqbhJQAAZ5YS3cJ46qmn9N133+nxxx/Xvn37ZIzR2LFjtXv3br3//vuqV6+eBgwYUOBVCQAAcPoqUYCYM2eOLrzwQo0ZM0aVK1f2D09KStI111yjpUuXavHixZowYUKJCwUAABVHiQLE9u3bdeGFF/61MKcz4GpDrVq11LdvX7399tslWQ0AAKhgShQgoqKi5HT+tYjY2Fjt3r07YJpq1aqVqAtsAABQ8ZQoQCQnJweEg2bNmumrr77yX4Uwxmjx4sWqXr16yaoEAAAVSokCRPfu3bVkyRL/91wMGTJE27dvV4cOHfTggw+qU6dOWr9+va6++upSKRYAAFQMJXqM85ZbblFCQoJSU1NVvXp13XzzzVq3bp2mTp2q9evXS5KuvvpqjR07thRKBQAAFYXDHN9xQylJTU3V5s2blZycrGrVqpX24k8qovXdZb5OAEV3cNWU8i4BQCHCi3B5ocQ9URakSpUqqlKlyqlYdJH0vWdoua0bAICzQakEiJSUFM2ZM0cbNmxQZmampk2bJinvSsSWLVvUvHlzRURElMaqAABABVDiADF16lTdf//9/icvHA6HP0Ds3btXHTp00GuvvaZbbrmlpKsCAAAVRImewvj000919913q3nz5po3b57uuOOOgPHnnXeeWrRooY8//rgkqwEAABVMia5ATJgwQXXq1NGSJUsUFRWlNWvW5JumefPm+vrrr0uyGgAAUMGU6ArE+vXr1bdvX0VFRQWdpmbNmtqzZ09JVgMAACqYEgUIr9er0NDQQqdJTU2V2+0uyWoAAEAFU6IA0aRJE61YsSLoeI/Ho2XLlql58+YlWQ0AAKhgShQgbrjhBq1du1ZPPfVUvnG5ubl64IEHtHnzZg0ePLgkqwEAABVMiXqizMnJUa9evbR8+XI1bNhQbrdbP//8s66++mqtXr1aW7duVa9evfTFF1/I4XCUZt2FGjA9f2NOABXHu4PblncJAApRlJ4oS3QFIjQ0VP/+97/1yCOPaN++ffrpp59kjNGHH36oAwcO6OGHH9a8efPKNDwAAIBTr9S+C8MYo40bN+rAgQOKiYlR06ZN5XK5tGXLFj3++OOaOXNmaaymSLgCAVRsXIEAKrYy/S4Mh8Ohc845x//z9u3b9eSTT2rWrFnyeDxlGiAAAMCpVaxbGCtWrFDXrl0VExOjypUr68orr9TGjRslSUeOHNHIkSPVuHFjTZs2TVWqVNFLL71UqkUDAIDyZX0FYs2aNerRo4eys7P9wz799FOtWrVKy5cvV//+/fXLL7+oRo0aevjhh3XrrbfSDwQAAGcY6ysQ48ePV3Z2tsaNG6e9e/dq7969euKJJ5SSkqKLL75YGzZs0JgxY7Rp0ybdc889hAcAAM5A1o0oa9WqpXPOOUeLFi0KGN61a1ctX75cEyZM0MiRI0u1SFs0ogQqNhpRAhXbKXmMc+/evWrbNv/B3759e0nSkCFDbBcJAABOM9YBwuPxFPjlWb5hCQkJJa8KAABUaCXqSAoAAJyditUPxLvvvquVK1cGDNu0aZMk6bLLLss3vcPh0Pz584uzKgAAUAEVK0Bs2rTJHxhOtGDBgnzD6MoaAIAzi3WA2LJly6moAwAAnEasA0RycvKpqAMAAJxGaEQJAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALAWUt4F4MyVmbpLe3/5Xge2/KyDW35Wxp+bZby5Orf/7Wrab1iB8/zyyev6dd6bhS6351MfKqZ63YBhh1K2adear5S6YbXSd25SdmaaQtxRiqvdSHU69lVyx8vlcJKXgdKy4IvP9dKLE7V+3VplZWWpceMmGjRkqG6/8y45OdbOCgQInDKbFv1TmxbNLta8EZWTFFm5WoHjQsLCA3423lx9Ofrqv+aNT1Jc7SY6ciBFqRvXKHXjGu34/kt1vOcFuULdxaoHwF8mjH9Wj44eJUmqV7++oqOi9eOPP+j+EfdqyVeL9P6HcwkRZwECBE6ZsOhYVWt5sSrXO0/xdc/V1q8/1q41XxVp3rqdrtC5V95WpGmNMQqNrKQG3a5Vcqd+iq5Syz9u56qFWj19rPb+vFI/z3lVLQYOL85bAfA/K7/7To+N+T85nU5Nf/tdDfx/10mSfvzhB13Rt7c++3SeJr84USNGPlDOleJUIyLilGnab5guuneSmvYbpmrNOyrEHXlK1uNwunTps5/ovKvuCAgPklSrfU817XeLJGnrinkyXu8pqQE4Wzw37ikZYzT05mH+8CBJLVq21LMTJkqSXhj/rHJycsqrRJQRAgROew6HQ2FRMUHHJ513oSQp50iGsg4dLKuygDNORkaGvlq8SJI0ZOjf842/esA1iomJ0f79+7Vs6ZKyLg9ljFsYqJBSN6zRyl0PKzszXWFRMYqvd56SO/ZVeGyi9bJyc7L9/3eF0QYCKK4f1q9Tdna2wsPD1bpNm3zjQ0ND1bZdey35arFWff8f9ejZqxyqRFmpcFcgli9frn79+qlGjRpyOBz6+OOPy7sklIN9v63VrjWLlbphtXat+Uo/ffiyFjxypbau+NR6WTtXL5QkxdRsoNCI6NIuFThrbPr9d0lS7Tp1FBJS8N+f9erVD5gWZ64KdwUiMzNTLVu21NChQ3X11VeffAacUcJjE9Wk71DVbNNVUYk15QpzK237Rv362TTt+e+3WjPzCYVFx6pGq0uKtLz0nZu0ecmHkqTGlw4+laUDZ7yDaXm3AOPi4oNOExefNy4tjduFZ7oKFyD69OmjPn36FHn6rKwsZWVlBQzLzcmWKzSstEtDGajfJX9oTGjYUhfdN1krpz6kP9cu0Y/vT1T1lhfL4XAUuqzsI4e0cupD8npyVK35RUru2PdUlQ2cFbKOHZMkhYUFP7+63Xm3CY8ePVomNaH8VLhbGLbGjRun2NjYgNfGz2eUd1koZQ6HQ82uvluSlLl3p9J3Fn55NDcnW99NuV+H92xXTI36an/Lk2VRJnBGc4fn9cGSnZ0ddBrfH3QRERFlUhPKz2kfIEaNGqX09PSAV5PLhpZ3WTgFKlVLVlhUrCQpc8+OoNN5cz36z2ujtG/jWkUm1lCnka8U+pQGgKKJjzv57Ym0gye/zYEzQ4W7hWHL7Xb7L5n5cPvizOVw5e2yXm9ugeONMVoz/XHtXr9M4bGJuvj+qYqIr1KWJQJnrIaNGkmSdmzfLo/HU2BDyi1bNgdMizPXaX8FAmePrENpyjp0QJIUEV+1wGnWvzde21d+obDoWF18/yuKrlqrwOkA2GvZqrVCQ0N17NgxrVu7Nt/4nJwcrVm9SpLU/vwLyro8lDECBE4bv3/5nmSMQiOiVbneefnG/zTnFW1e8oFCwqPUacTLiqnZoByqBM5cMTEx6ta9hyTp7RnT8o3/6MMPlJGRoYSEBF3SuUsZV4eyVuECxOHDh7V+/XqtX79ekrRlyxatX79e27dvL9/CcMpl7PpD6955Vhm7/ggYnpuTpQ3zp2vjF29Lkhr3GSJnSGjANL/9+11tnD9DrjC3Ot47SfF1zy2zuoGzyUOPjJbD4dCM6W/p/X/+9WV5P/7wgx55cKQkacQDDxX6pAbODA5jjCnvIo63dOlSde3aNd/wIUOGaObMmUVaxoDpa0q5KhTHvt/X67sp9/t/9hw7Kq8nW66w8IAeIbs/9p4iK1dT2vaNWvz4DZIkd6V4Rfzv2zgP7d6i3Oy8x8fqXnyl2gwZE/AI59GDqfr8wcskY+SOqazoqrWD1nThnc8VqzdLlK53B7ct7xJQAs+Ne1pjHx0j6a9v4/z555/k9XrV57K++mDOJ3K5XOVcJUoivAgtJCtcI8ouXbqogmUaFJPJ9Sj7cHq+4bnZx/yBQJL/C64iE2vo3P63a/8fP+rQ7m06nLJN3twcuStVVuXmF6nuJf1VrVmHfMvz5uZI/9tnsjIOKCvjQNCaju/WGkDxPDxqtJq3aKmXJ0/SurVrtCclRc2aNdegIUN1x113Ex7OEhXuCkRp4AoEULFxBQKo2IpyBaLCtYEAAAAVHwECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGCNAAEAAKwRIAAAgDUCBAAAsEaAAAAA1ggQAADAGgECAABYI0AAAABrBAgAAGDNYYwx5V0EEExWVpbGjRunUaNGye12l3c5AE7AMXr2IkCgQsvIyFBsbKzS09MVExNT3uUAOAHH6NmLWxgAAMAaAQIAAFgjQAAAAGsECFRobrdbjz32GI2zgAqKY/TsRSNKAABgjSsQAADAGgECAABYI0AAAABrBAgAZ5XVq1fL7XbrhhtuEE3AgOIjQAAosa1bt8rhcOimm24KGN6lSxc5HI4yqaEo60pLS9O1116riy66SDNmzCiz2oAzEQECOM34PqyPf4WFhal27dq6/vrr9eOPP5Z3iRXWTTfdpKioKM2dO1dhYWHlXQ5wWgsp7wIAFE+DBg104403SpIOHz6slStXavbs2ZozZ46++uordezYsZwrlGbNmqUjR45UiHVt2bJFrVq10pQpUxQbG1smNQFnMgIEcJpq2LChxo4dGzBszJgxevrppzV69GgtWbKkfAo7Tp06dSrMuurVq5dvewEoPm5hAGeQe+65R5K0atUqSZLD4VCXLl20a9cu3XTTTapWrZqcTqeWLl3qn2f58uXq16+fEhMT5Xa71ahRI40ZM6bAv+Zzc3P13HPPqWHDhgoPD1fDhg01btw4eb3eAusprF3CvHnz1Lt3byUkJCg8PFx169bVoEGD9NNPPwVMl52drcmTJ+v8889XpUqVFB0drXPPPVcjR47UwYMHT7ouj8ejSZMmqWXLloqIiFBsbKy6du2q+fPn55t25syZcjgcmjlzphYvXqxOnTopKipKCQkJGjJkiPbv31/gewHORlyBAM4gBX2A7t+/Xx06dFDlypU1cOBAZWdn+792+bXXXtOdd96p+Ph49evXT1WqVNGqVav09NNPa8mSJVqyZElAW4Fbb71V06dPV7169XTXXXfp2LFjmjhxor799lurOh966CFNmDBBlStXVv/+/VW1alXt2LFDixYtUtu2bdWsWTNJ0rFjx9S7d28tX75cjRo10tChQ+V2u/X777/rtdde0+DBgxUfHx90PcYYDRw4UHPmzFHjxo111113KTMzU//61790+eWXa/Lkybr33nvzzffpp5/qs88+U79+/XTHHXdo+fLlmjVrlv744w+tWLHC6r0CZywD4LSyZcsWI8n07t0737jRo0cbSaZLly7GGGMkGUlm6NChxuPxBEz7888/m5CQENO6dWuzf//+gHHjxo0zkszzzz/vH7ZkyRIjybRs2dIcPnzYP3znzp0mMTHRSDJDhgwJWE7nzp3NiaeZ+fPnG0mmefPmZt++fQHjcnJyTEpKiv/nBx980EgygwYNyld/WlqaOXToUKHrmjVrlpFkOnfubLKysvzDd+zYYapWrWpCQ0PN5s2b/cNnzJhhJJmQkBCzYsUK/3CPx2O6dOliJJnvvvvOADCGWxjAaWrTpk0aO3asxo4dqwceeECdOnXS008/rfDwcD3zzDP+6cLCwjR+/Hi5XK6A+V9//XV5PB699NJLqly5csC4hx56SFWqVNHs2bP9w2bNmiVJevTRRxUVFeUfXrNmTd13331FrvuVV16RJE2ePFkJCQkB40JCQpSUlCQp73bJ66+/rtjYWE2ePDlf/bGxsYqOji50XTNnzpQkjR8/PuBKSq1atTRixAjl5OTovffeyzff9ddfr4suusj/s8vl0pAhQyT9dXsIONtxCwM4Tf3xxx96/PHHJUmhoaFKSkrS9ddfr0ceeUTNmzf3T1evXj0lJibmm3/lypWSpAULFmjRokX5xoeGhmrDhg3+n3/44QdJ0sUXX5xv2oKGBfP999/L7Xarc+fOhU63YcMGZWRkqEePHoXepijMunXrFBERofPPPz/fuC5dukiS1q9fn29cmzZt8g2rVauWpLy+JAAQIIDTVu/evbVgwYKTTuf7i/5EBw4ckCQ9/fTTRVpfenq6nE5ngWEk2DoKkpaWppo1a8rpLPwCqO+DumbNmkVe9okyMjJUu3btAsdVq1ZNUt77OlFBj3mGhOSdLnNzc4tdD3Am4RYGcIYL9hSEryFlRkaGjDFBXz6xsbHyer3at29fvmXt2bOnyPXExcUpJSUl6JMbx08nSbt27Srysk8UExMTtDbfcN92AGCHAAGcpS644AJJf93KOJmWLVtKkr7++ut84woaFsz555+vrKwsLVu2rNDpmjRpopiYGK1atSrgcU0brVu31tGjR/X999/nG+dbf6tWrYq1bOBsR4AAzlJ33nmnQkJCdM8992jHjh35xqelpWndunX+nwcPHixJeuKJJ5SZmekfvmvXLk2ePLnI673rrrskSffdd5//NoqPx+PxXxkICQnRbbfdpvT0dN133335bh2kp6fr8OHDha7L1/Bx1KhRysnJCah54sSJCgkJ0Q033FDk2gH8hTYQwFmqWbNmmjp1qu644w41adJEl112mRo0aKCMjAxt3rxZy5Yt00033aTXXntNUl6jw6FDh2rGjBlq3ry5rrrqKmVlZen999/XhRdeqM8++6xI673sssv0wAMP6Pnnn1ejRo101VVXqWrVqtq1a5cWL16sBx54QMOHD5eUF1ZWrlypd955RytXrlSfPn3kdru1efNmLViwQCtWrCj0CsKgQYM0Z84cffLJJ2rRooUuv/xyfz8Q+/fv1wsvvKD69euXdFMCZyUCBHAWu+WWW9SqVStNnDhRy5cv17x58xQbG6s6depoxIgR/r/gfd588001btxYb775pqZMmaJatWpp5MiRuvbaa4scICRpwoQJ6tChg6ZMmaIPP/xQx44dU/Xq1dWtWzf17NnTP114eLgWLlyoKVOm6N1339Wbb74pl8ulOnXq6Pbbb1fdunULXY/D4dCHH36oyZMn6+2339bLL7+ssLAwtWnTRiNHjtQVV1xhtb0A/MVhjm8lBQAAUAS0gQAAANYIEAAAwBoBAgAAWCNAAAAAawQIAABgjQABAACsESAAAIA1AgQAALBGgAAAANYIEAAAwBoBAgAAWCNAAAAAa/8/ezKJMS8pvpsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluar en el conjunto de validación\n",
    "accuracy = best_model.evaluate(X_test, y_test, verbose=0)[0]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy en el conjunto de validación: {accuracy}\")\n",
    "\n",
    "# Generar predicciones en el conjunto de prueba\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.where(y_pred_probs > 0.5, 1, 0)  # Convertir probabilidades en predicciones binarias\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision:.8f}')\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "# Graficar la matriz de confusión\n",
    "# Graficar la matriz de confusión con matshow\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.matshow(conf_matrix, cmap='Blues', fignum=1)  # Utilizar fignum=1 para evitar la creación de una nueva figura\n",
    "plt.title('Matriz de Confusión de Red Neuronal', pad=20, fontsize=18)\n",
    "plt.xlabel('Predicción', fontsize=14)\n",
    "plt.ylabel('Real', fontsize=14)\n",
    "\n",
    "# Agregar las anotaciones de los valores en la matriz\n",
    "for (i, j), val in np.ndenumerate(conf_matrix):\n",
    "    plt.text(j, i, f'{val}', ha='center', va='center', fontsize=16, color=\"black\")\n",
    "\n",
    "# Remover la barra de color\n",
    "plt.gca().set_frame_on(False)  # Remueve el borde alrededor de la matriz\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_Cherbourg</th>\n",
       "      <th>Embarked_Queenstown</th>\n",
       "      <th>Embarked_Southampton</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Large</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Small</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.1417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.7875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>23.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>339</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>430</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>445</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.1125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>456</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>490</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>554</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>623</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.7417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>644</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>665</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>693</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>710</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>752</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.4750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>763</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>789</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>805</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.9750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>822</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>829</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>839</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Age     Fare  Embarked_Cherbourg  \\\n",
       "36            37         1       3  47.0   7.2292                 1.0   \n",
       "64            66         1       3  19.0  15.2458                 1.0   \n",
       "73            75         1       3  32.0  56.4958                 0.0   \n",
       "80            82         1       3  29.0   9.5000                 0.0   \n",
       "106          108         1       3  47.0   7.7750                 0.0   \n",
       "124          126         1       3  12.0  11.2417                 1.0   \n",
       "126          128         1       3  24.0   7.1417                 0.0   \n",
       "145          147         1       3  27.0   7.7958                 0.0   \n",
       "164          166         1       3   9.0  20.5250                 0.0   \n",
       "203          205         1       3  18.0   8.0500                 0.0   \n",
       "206          208         1       3  26.0  18.7875                 1.0   \n",
       "219          221         1       3  16.0   8.0500                 0.0   \n",
       "260          262         1       3   3.0  31.3875                 0.0   \n",
       "266          268         1       3  25.0   7.7750                 0.0   \n",
       "270          272         1       3  25.0   0.0000                 0.0   \n",
       "282          284         1       3  19.0   8.0500                 0.0   \n",
       "285          287         1       3  30.0   9.5000                 0.0   \n",
       "300          302         1       3  47.0  23.2500                 0.0   \n",
       "337          339         1       3  45.0   8.0500                 0.0   \n",
       "347          349         1       3   3.0  15.9000                 0.0   \n",
       "390          392         1       3  21.0   7.7958                 0.0   \n",
       "399          401         1       3  39.0   7.9250                 0.0   \n",
       "413          415         1       3  44.0   7.9250                 0.0   \n",
       "428          430         1       3  32.0   8.0500                 0.0   \n",
       "443          445         1       3  47.0   8.1125                 0.0   \n",
       "454          456         1       3  29.0   7.8958                 1.0   \n",
       "488          490         1       3   9.0  15.9000                 0.0   \n",
       "508          510         1       3  26.0  56.4958                 0.0   \n",
       "509          511         1       3  29.0   7.7500                 0.0   \n",
       "552          554         1       3  22.0   7.2250                 1.0   \n",
       "568          570         1       3  32.0   7.8542                 0.0   \n",
       "578          580         1       3  32.0   7.9250                 0.0   \n",
       "621          623         1       3  20.0  15.7417                 1.0   \n",
       "642          644         1       3  47.0  56.4958                 0.0   \n",
       "663          665         1       3  20.0   7.9250                 0.0   \n",
       "691          693         1       3  47.0  56.4958                 0.0   \n",
       "708          710         1       3  19.0  15.2458                 1.0   \n",
       "743          745         1       3  31.0   7.9250                 0.0   \n",
       "750          752         1       3   6.0  12.4750                 0.0   \n",
       "761          763         1       3  20.0   7.2292                 1.0   \n",
       "787          789         1       3   1.0  20.5750                 0.0   \n",
       "802          804         1       3   0.0   8.5167                 1.0   \n",
       "803          805         1       3  27.0   6.9750                 0.0   \n",
       "820          822         1       3  27.0   8.6625                 0.0   \n",
       "827          829         1       3  47.0   7.7500                 0.0   \n",
       "836          839         1       3  32.0  56.4958                 0.0   \n",
       "867          870         1       3   4.0  11.1333                 0.0   \n",
       "\n",
       "     Embarked_Queenstown  Embarked_Southampton  Alone  Large  Medium  Small  \\\n",
       "36                   0.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "64                   0.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "73                   0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "80                   0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "106                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "124                  0.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "126                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "145                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "164                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "203                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "206                  0.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "219                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "260                  0.0                   1.0    0.0    1.0     0.0    0.0   \n",
       "266                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "270                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "282                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "285                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "300                  1.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "337                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "347                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "390                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "399                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "413                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "428                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "443                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "454                  0.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "488                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "508                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "509                  1.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "552                  0.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "568                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "578                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "621                  0.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "642                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "663                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "691                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "708                  0.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "743                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "750                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "761                  0.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "787                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "802                  0.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "803                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "820                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "827                  1.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "836                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "867                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "\n",
       "     Female  Male  \n",
       "36      0.0   1.0  \n",
       "64      0.0   1.0  \n",
       "73      0.0   1.0  \n",
       "80      0.0   1.0  \n",
       "106     0.0   1.0  \n",
       "124     0.0   1.0  \n",
       "126     0.0   1.0  \n",
       "145     0.0   1.0  \n",
       "164     0.0   1.0  \n",
       "203     0.0   1.0  \n",
       "206     0.0   1.0  \n",
       "219     0.0   1.0  \n",
       "260     0.0   1.0  \n",
       "266     0.0   1.0  \n",
       "270     0.0   1.0  \n",
       "282     0.0   1.0  \n",
       "285     0.0   1.0  \n",
       "300     0.0   1.0  \n",
       "337     0.0   1.0  \n",
       "347     0.0   1.0  \n",
       "390     0.0   1.0  \n",
       "399     0.0   1.0  \n",
       "413     0.0   1.0  \n",
       "428     0.0   1.0  \n",
       "443     0.0   1.0  \n",
       "454     0.0   1.0  \n",
       "488     0.0   1.0  \n",
       "508     0.0   1.0  \n",
       "509     0.0   1.0  \n",
       "552     0.0   1.0  \n",
       "568     0.0   1.0  \n",
       "578     0.0   1.0  \n",
       "621     0.0   1.0  \n",
       "642     0.0   1.0  \n",
       "663     0.0   1.0  \n",
       "691     0.0   1.0  \n",
       "708     0.0   1.0  \n",
       "743     0.0   1.0  \n",
       "750     0.0   1.0  \n",
       "761     0.0   1.0  \n",
       "787     0.0   1.0  \n",
       "802     0.0   1.0  \n",
       "803     0.0   1.0  \n",
       "820     0.0   1.0  \n",
       "827     0.0   1.0  \n",
       "836     0.0   1.0  \n",
       "867     0.0   1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['Male'] == 1)&(train['Survived'] == 1)&(train['Pclass'] == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Group_Size</th>\n",
       "      <th>Embarked_Cherbourg</th>\n",
       "      <th>Embarked_Queenstown</th>\n",
       "      <th>Embarked_Southampton</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Age     Fare  Group_Size  \\\n",
       "1              2         1       1  38.0  71.2833           3   \n",
       "2              3         1       3  26.0   7.9250           0   \n",
       "3              4         1       1  35.0  53.1000           3   \n",
       "8              9         1       3  27.0  11.1333           3   \n",
       "9             10         1       2  14.0  30.0708           3   \n",
       "..           ...       ...     ...   ...      ...         ...   \n",
       "872          875         1       2  28.0  24.0000           3   \n",
       "873          876         1       3  15.0   7.2250           0   \n",
       "877          880         1       1  56.0  83.1583           3   \n",
       "878          881         1       2  25.0  26.0000           3   \n",
       "885          888         1       1  19.0  30.0000           0   \n",
       "\n",
       "     Embarked_Cherbourg  Embarked_Queenstown  Embarked_Southampton  Female  \\\n",
       "1                   1.0                  0.0                   0.0     1.0   \n",
       "2                   0.0                  0.0                   1.0     1.0   \n",
       "3                   0.0                  0.0                   1.0     1.0   \n",
       "8                   0.0                  0.0                   1.0     1.0   \n",
       "9                   1.0                  0.0                   0.0     1.0   \n",
       "..                  ...                  ...                   ...     ...   \n",
       "872                 1.0                  0.0                   0.0     1.0   \n",
       "873                 1.0                  0.0                   0.0     1.0   \n",
       "877                 1.0                  0.0                   0.0     1.0   \n",
       "878                 0.0                  0.0                   1.0     1.0   \n",
       "885                 0.0                  0.0                   1.0     1.0   \n",
       "\n",
       "     Male  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "8     0.0  \n",
       "9     0.0  \n",
       "..    ...  \n",
       "872   0.0  \n",
       "873   0.0  \n",
       "877   0.0  \n",
       "878   0.0  \n",
       "885   0.0  \n",
       "\n",
       "[231 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['Female'] == 1)&(train['Survived'] == 1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
