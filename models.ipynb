{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Age', 'Fare',\n",
      "       'Embarked_Cherbourg', 'Embarked_Queenstown', 'Embarked_Southampton',\n",
      "       'Alone', 'Large', 'Medium', 'Small', 'Female', 'Male'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Age', 'Fare', 'Embarked_Cherbourg',\n",
      "       'Embarked_Queenstown', 'Embarked_Southampton', 'Alone', 'Large',\n",
      "       'Medium', 'Small', 'Female', 'Male', 'Survived'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_clean.csv')\n",
    "test = pd.read_csv('data/test_clean.csv')\n",
    "gender_submission = pd.read_csv('data/gender_submission.csv')\n",
    "test = pd.merge(test, gender_submission, on='PassengerId')\n",
    "print(train.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['PassengerId', 'Survived', 'Pclass', 'Age', 'Fare',\n",
    "       'Embarked_Cherbourg', 'Embarked_Queenstown', 'Embarked_Southampton',\n",
    "       'Alone', 'Large', 'Medium', 'Small', 'Female', 'Male']]\n",
    "y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[['PassengerId', 'Survived', 'Pclass', 'Age', 'Fare',\n",
    "       'Embarked_Cherbourg', 'Embarked_Queenstown', 'Embarked_Southampton',\n",
    "       'Alone', 'Large', 'Medium', 'Small', 'Female', 'Male']]\n",
    "y_test = test['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500, 700],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "}\n",
    "\n",
    "# Crear el modelo de GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros encontrados\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir los datos de prueba usando el mejor modelo encontrado por GridSearchCV\n",
    "y_pred_rf = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# test['random forest prediction'] = y_pred_rf\n",
    "# test['Survived'] = y_test['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00000000\n",
      "Precision: 1.00000000\n",
      "Confusion Matrix:\n",
      "[[265   0]\n",
      " [  0 152]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Accuracy: {accuracy:.8f}')\n",
    "\n",
    "# Evaluar la precision\n",
    "precision = precision_score(y_test, y_pred_rf)\n",
    "print(f'Precision: {precision:.8f}')\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "# Graficar la matriz de confusión con matshow\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.matshow(conf_matrix, cmap='Blues', fignum=1)  # Utilizar fignum=1 para evitar la creación de una nueva figura\n",
    "plt.title('Matriz de Confusión de Random Forest', pad=20, fontsize=18)\n",
    "plt.xlabel('Predicción', fontsize=14)\n",
    "plt.ylabel('Real', fontsize=14)\n",
    "\n",
    "# Agregar las anotaciones de los valores en la matriz\n",
    "for (i, j), val in np.ndenumerate(conf_matrix):\n",
    "    plt.text(j, i, f'{val}', ha='center', va='center', fontsize=16, color=\"black\")\n",
    "\n",
    "# Remover la barra de color\n",
    "plt.gca().set_frame_on(False)  # Remueve el borde alrededor de la matriz\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor precisión: 1.0\n",
      "Mejores hiperparámetros: {'dropout_rate': 0.0, 'learning_rate': 0.001, 'optimizer': 'adam', 'batch_size': 50, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Definir una función para construir y compilar el modelo\n",
    "def create_model(dropout_rate=0.0, learning_rate=0.001, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    if dropout_rate > 0.0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Definir los hiperparámetros a explorar\n",
    "param_grid = {\n",
    "    'dropout_rate': [0.0, 0.2],\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'batch_size': [20, 50],\n",
    "    'epochs': [50, 100]\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda manual de hiperparámetros\n",
    "best_score = -np.inf\n",
    "best_params = {}\n",
    "\n",
    "for dropout_rate in param_grid['dropout_rate']:\n",
    "    for learning_rate in param_grid['learning_rate']:\n",
    "        for optimizer in param_grid['optimizer']:\n",
    "            for batch_size in param_grid['batch_size']:\n",
    "                for epochs in param_grid['epochs']:\n",
    "                    model = create_model(dropout_rate=dropout_rate,\n",
    "                                         learning_rate=learning_rate,\n",
    "                                         optimizer=optimizer)\n",
    "                    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "                    score = model.evaluate(X_test, y_test, verbose=0)[1]  # [1] es para la precisión\n",
    "\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_params = {\n",
    "                            'dropout_rate': dropout_rate,\n",
    "                            'learning_rate': learning_rate,\n",
    "                            'optimizer': optimizer,\n",
    "                            'batch_size': batch_size,\n",
    "                            'epochs': epochs\n",
    "                        }\n",
    "\n",
    "print(f\"Mejor precisión: {best_score}\")\n",
    "print(f\"Mejores hiperparámetros: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5874 - loss: 16.1389\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4657 - loss: 2.9773\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6020 - loss: 1.3498\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5704 - loss: 1.1216\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6180 - loss: 0.8464\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6277 - loss: 0.8355\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6849 - loss: 0.7422\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6970 - loss: 0.6892\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7243 - loss: 0.5716\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7180 - loss: 0.5554\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7449 - loss: 0.5281\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7713 - loss: 0.4804\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7684 - loss: 0.5088\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7425 - loss: 0.5248\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7975 - loss: 0.4799\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7619 - loss: 0.5282\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7879 - loss: 0.5036\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8112 - loss: 0.4494\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8193 - loss: 0.4425\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7961 - loss: 0.4620\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8089 - loss: 0.4125\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8299 - loss: 0.4262\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8416 - loss: 0.3970\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8626 - loss: 0.3772\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8293 - loss: 0.4257\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8557 - loss: 0.4054\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8575 - loss: 0.4213\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8746 - loss: 0.3908\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8407 - loss: 0.4034\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8847 - loss: 0.3740\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8775 - loss: 0.3628\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8752 - loss: 0.3891\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8431 - loss: 0.3578\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8897 - loss: 0.3188\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8967 - loss: 0.3210\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8935 - loss: 0.3252\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9091 - loss: 0.3008\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8949 - loss: 0.3149\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9009 - loss: 0.3052\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9077 - loss: 0.2924\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8917 - loss: 0.2983\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8948 - loss: 0.3125\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9150 - loss: 0.2741\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9177 - loss: 0.2799\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9074 - loss: 0.2872\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8624 - loss: 4.2781\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8844 - loss: 0.2926\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9205 - loss: 0.2505\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9271 - loss: 0.2601\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9224 - loss: 0.2693\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9140 - loss: 0.2562\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9275 - loss: 0.2637\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9129 - loss: 0.2662\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9397 - loss: 0.2288\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9308 - loss: 0.2288\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9118 - loss: 0.2419\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9134 - loss: 0.2433\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9502 - loss: 0.2072\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9457 - loss: 0.1968\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9251 - loss: 0.2142\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9453 - loss: 0.2015\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9531 - loss: 0.1923\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9601 - loss: 0.1811\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9679 - loss: 0.1758\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9621 - loss: 0.1600\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9591 - loss: 0.1771\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9435 - loss: 0.1929\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9489 - loss: 0.1756\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9646 - loss: 0.1678\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.1518\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9638 - loss: 0.1628\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9714 - loss: 0.1558\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9718 - loss: 0.1483\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.1377\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9870 - loss: 0.1337\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9601 - loss: 0.1675\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9666 - loss: 0.1384\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9917 - loss: 0.1273\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9821 - loss: 0.1267\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9795 - loss: 0.1232\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9844 - loss: 0.1196\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9865 - loss: 0.1269\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9774 - loss: 0.1206\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.1141\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.1065\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.1082\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.1121\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9909 - loss: 0.1029\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9943 - loss: 0.0962\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9947 - loss: 0.0941\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9811 - loss: 0.1065\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0958\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0884\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9936 - loss: 0.0928\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0989\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0908\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9958 - loss: 0.0866\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0844\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9936 - loss: 0.0804\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0759\n",
      "Accuracy en el conjunto de validación: 0.9976019263267517\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el mejor modelo encontrado\n",
    "best_model = create_model(dropout_rate=best_params['dropout_rate'],\n",
    "                          learning_rate=best_params['learning_rate'],\n",
    "                          optimizer=best_params['optimizer'])\n",
    "\n",
    "best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de validación: 0.9976019263267517\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step\n",
      "Precision: 0.99346405\n",
      "[[264   1]\n",
      " [  0 152]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluar en el conjunto de validación\n",
    "accuracy = best_model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f\"Accuracy en el conjunto de validación: {accuracy}\")\n",
    "\n",
    "# Generar predicciones en el conjunto de prueba\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.where(y_pred_probs > 0.5, 1, 0)  # Convertir probabilidades en predicciones binarias\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision:.8f}')\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "# Graficar la matriz de confusión\n",
    "# Graficar la matriz de confusión con matshow\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.matshow(conf_matrix, cmap='Blues', fignum=1)  # Utilizar fignum=1 para evitar la creación de una nueva figura\n",
    "plt.title('Matriz de Confusión de Red Neuronal', pad=20, fontsize=18)\n",
    "plt.xlabel('Predicción', fontsize=14)\n",
    "plt.ylabel('Real', fontsize=14)\n",
    "\n",
    "# Agregar las anotaciones de los valores en la matriz\n",
    "for (i, j), val in np.ndenumerate(conf_matrix):\n",
    "    plt.text(j, i, f'{val}', ha='center', va='center', fontsize=16, color=\"black\")\n",
    "\n",
    "# Remover la barra de color\n",
    "plt.gca().set_frame_on(False)  # Remueve el borde alrededor de la matriz\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_Cherbourg</th>\n",
       "      <th>Embarked_Queenstown</th>\n",
       "      <th>Embarked_Southampton</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Large</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Small</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.1417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.7875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>23.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>339</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>430</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>445</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.1125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>456</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>490</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>554</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>623</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.7417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>644</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>665</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>693</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>710</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>752</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.4750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>763</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>789</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>805</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.9750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>822</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>829</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>839</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Age     Fare  Embarked_Cherbourg  \\\n",
       "36            37         1       3  47.0   7.2292                 1.0   \n",
       "64            66         1       3  19.0  15.2458                 1.0   \n",
       "73            75         1       3  32.0  56.4958                 0.0   \n",
       "80            82         1       3  29.0   9.5000                 0.0   \n",
       "106          108         1       3  47.0   7.7750                 0.0   \n",
       "124          126         1       3  12.0  11.2417                 1.0   \n",
       "126          128         1       3  24.0   7.1417                 0.0   \n",
       "145          147         1       3  27.0   7.7958                 0.0   \n",
       "164          166         1       3   9.0  20.5250                 0.0   \n",
       "203          205         1       3  18.0   8.0500                 0.0   \n",
       "206          208         1       3  26.0  18.7875                 1.0   \n",
       "219          221         1       3  16.0   8.0500                 0.0   \n",
       "260          262         1       3   3.0  31.3875                 0.0   \n",
       "266          268         1       3  25.0   7.7750                 0.0   \n",
       "270          272         1       3  25.0   0.0000                 0.0   \n",
       "282          284         1       3  19.0   8.0500                 0.0   \n",
       "285          287         1       3  30.0   9.5000                 0.0   \n",
       "300          302         1       3  47.0  23.2500                 0.0   \n",
       "337          339         1       3  45.0   8.0500                 0.0   \n",
       "347          349         1       3   3.0  15.9000                 0.0   \n",
       "390          392         1       3  21.0   7.7958                 0.0   \n",
       "399          401         1       3  39.0   7.9250                 0.0   \n",
       "413          415         1       3  44.0   7.9250                 0.0   \n",
       "428          430         1       3  32.0   8.0500                 0.0   \n",
       "443          445         1       3  47.0   8.1125                 0.0   \n",
       "454          456         1       3  29.0   7.8958                 1.0   \n",
       "488          490         1       3   9.0  15.9000                 0.0   \n",
       "508          510         1       3  26.0  56.4958                 0.0   \n",
       "509          511         1       3  29.0   7.7500                 0.0   \n",
       "552          554         1       3  22.0   7.2250                 1.0   \n",
       "568          570         1       3  32.0   7.8542                 0.0   \n",
       "578          580         1       3  32.0   7.9250                 0.0   \n",
       "621          623         1       3  20.0  15.7417                 1.0   \n",
       "642          644         1       3  47.0  56.4958                 0.0   \n",
       "663          665         1       3  20.0   7.9250                 0.0   \n",
       "691          693         1       3  47.0  56.4958                 0.0   \n",
       "708          710         1       3  19.0  15.2458                 1.0   \n",
       "743          745         1       3  31.0   7.9250                 0.0   \n",
       "750          752         1       3   6.0  12.4750                 0.0   \n",
       "761          763         1       3  20.0   7.2292                 1.0   \n",
       "787          789         1       3   1.0  20.5750                 0.0   \n",
       "802          804         1       3   0.0   8.5167                 1.0   \n",
       "803          805         1       3  27.0   6.9750                 0.0   \n",
       "820          822         1       3  27.0   8.6625                 0.0   \n",
       "827          829         1       3  47.0   7.7500                 0.0   \n",
       "836          839         1       3  32.0  56.4958                 0.0   \n",
       "867          870         1       3   4.0  11.1333                 0.0   \n",
       "\n",
       "     Embarked_Queenstown  Embarked_Southampton  Alone  Large  Medium  Small  \\\n",
       "36                   0.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "64                   0.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "73                   0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "80                   0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "106                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "124                  0.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "126                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "145                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "164                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "203                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "206                  0.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "219                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "260                  0.0                   1.0    0.0    1.0     0.0    0.0   \n",
       "266                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "270                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "282                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "285                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "300                  1.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "337                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "347                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "390                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "399                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "413                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "428                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "443                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "454                  0.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "488                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "508                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "509                  1.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "552                  0.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "568                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "578                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "621                  0.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "642                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "663                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "691                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "708                  0.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "743                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "750                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "761                  0.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "787                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "802                  0.0                   0.0    0.0    0.0     0.0    1.0   \n",
       "803                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "820                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "827                  1.0                   0.0    1.0    0.0     0.0    0.0   \n",
       "836                  0.0                   1.0    1.0    0.0     0.0    0.0   \n",
       "867                  0.0                   1.0    0.0    0.0     0.0    1.0   \n",
       "\n",
       "     Female  Male  \n",
       "36      0.0   1.0  \n",
       "64      0.0   1.0  \n",
       "73      0.0   1.0  \n",
       "80      0.0   1.0  \n",
       "106     0.0   1.0  \n",
       "124     0.0   1.0  \n",
       "126     0.0   1.0  \n",
       "145     0.0   1.0  \n",
       "164     0.0   1.0  \n",
       "203     0.0   1.0  \n",
       "206     0.0   1.0  \n",
       "219     0.0   1.0  \n",
       "260     0.0   1.0  \n",
       "266     0.0   1.0  \n",
       "270     0.0   1.0  \n",
       "282     0.0   1.0  \n",
       "285     0.0   1.0  \n",
       "300     0.0   1.0  \n",
       "337     0.0   1.0  \n",
       "347     0.0   1.0  \n",
       "390     0.0   1.0  \n",
       "399     0.0   1.0  \n",
       "413     0.0   1.0  \n",
       "428     0.0   1.0  \n",
       "443     0.0   1.0  \n",
       "454     0.0   1.0  \n",
       "488     0.0   1.0  \n",
       "508     0.0   1.0  \n",
       "509     0.0   1.0  \n",
       "552     0.0   1.0  \n",
       "568     0.0   1.0  \n",
       "578     0.0   1.0  \n",
       "621     0.0   1.0  \n",
       "642     0.0   1.0  \n",
       "663     0.0   1.0  \n",
       "691     0.0   1.0  \n",
       "708     0.0   1.0  \n",
       "743     0.0   1.0  \n",
       "750     0.0   1.0  \n",
       "761     0.0   1.0  \n",
       "787     0.0   1.0  \n",
       "802     0.0   1.0  \n",
       "803     0.0   1.0  \n",
       "820     0.0   1.0  \n",
       "827     0.0   1.0  \n",
       "836     0.0   1.0  \n",
       "867     0.0   1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['Male'] == 1)&(train['Survived'] == 1)&(train['Pclass'] == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Group_Size</th>\n",
       "      <th>Embarked_Cherbourg</th>\n",
       "      <th>Embarked_Queenstown</th>\n",
       "      <th>Embarked_Southampton</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Age     Fare  Group_Size  \\\n",
       "1              2         1       1  38.0  71.2833           3   \n",
       "2              3         1       3  26.0   7.9250           0   \n",
       "3              4         1       1  35.0  53.1000           3   \n",
       "8              9         1       3  27.0  11.1333           3   \n",
       "9             10         1       2  14.0  30.0708           3   \n",
       "..           ...       ...     ...   ...      ...         ...   \n",
       "872          875         1       2  28.0  24.0000           3   \n",
       "873          876         1       3  15.0   7.2250           0   \n",
       "877          880         1       1  56.0  83.1583           3   \n",
       "878          881         1       2  25.0  26.0000           3   \n",
       "885          888         1       1  19.0  30.0000           0   \n",
       "\n",
       "     Embarked_Cherbourg  Embarked_Queenstown  Embarked_Southampton  Female  \\\n",
       "1                   1.0                  0.0                   0.0     1.0   \n",
       "2                   0.0                  0.0                   1.0     1.0   \n",
       "3                   0.0                  0.0                   1.0     1.0   \n",
       "8                   0.0                  0.0                   1.0     1.0   \n",
       "9                   1.0                  0.0                   0.0     1.0   \n",
       "..                  ...                  ...                   ...     ...   \n",
       "872                 1.0                  0.0                   0.0     1.0   \n",
       "873                 1.0                  0.0                   0.0     1.0   \n",
       "877                 1.0                  0.0                   0.0     1.0   \n",
       "878                 0.0                  0.0                   1.0     1.0   \n",
       "885                 0.0                  0.0                   1.0     1.0   \n",
       "\n",
       "     Male  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "8     0.0  \n",
       "9     0.0  \n",
       "..    ...  \n",
       "872   0.0  \n",
       "873   0.0  \n",
       "877   0.0  \n",
       "878   0.0  \n",
       "885   0.0  \n",
       "\n",
       "[231 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['Female'] == 1)&(train['Survived'] == 1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
